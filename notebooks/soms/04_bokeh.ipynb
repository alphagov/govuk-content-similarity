{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "os.chdir('../../')\n",
    "from src.utils.helper_som import get_minimal_distance_factors\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import cm\n",
    "from bokeh.colors import RGB\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import ColumnDataSource, figure, output_file, show\n",
    "from bokeh.io import curdoc, show, output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data, normed document vectors and som\n",
    "df_sample = pd.read_pickle(filepath_or_buffer='data/processed/df_sample.pkl')\n",
    "normed_array_doc_vec = np.load(file='data/processed/doc_vec_norm_sample.npy')\n",
    "with open('data/processed/som.p', 'rb') as infile:\n",
    "    som = pickle.load(infile)\n",
    "\n",
    "# compute parameters\n",
    "len_vector = normed_array_doc_vec.shape[1]\n",
    "x, y = get_minimal_distance_factors(n=5 * np.sqrt(normed_array_doc_vec.shape[0]))\n",
    "\n",
    "# will consider all the sample mapped into a specific neuron as a cluster.\n",
    "# to identify each cluster more easily, will translate the bi-dimensional indices\n",
    "# of the neurons on the SOM into mono-dimensional indices.\n",
    "# each neuron represents a cluster\n",
    "winner_coordinates = np.array([som.winner(x) for x in normed_array_doc_vec]).T\n",
    "# with np.ravel_multi_index, we convert the bi-dimensional coordinates to a mono-dimensional index\n",
    "cluster_index = np.ravel_multi_index(multi_index=winner_coordinates, dims=(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following three lines, we return:\n",
    "- position of neurons on a euclidean plane that reflects chosen topology in meshgrids xx, yy e.g. (1,4) -> xx[1,4], yy[1,4]\n",
    "- distance map of the weights\n",
    "- weights of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = som.get_euclidean_coordinates()\n",
    "umatrix = som.distance_map() \n",
    "weights = som.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_centres_column = []\n",
    "tile_centres_row = []\n",
    "hex_colours = []\n",
    "for i in range(weights.shape[0]):\n",
    "    for j in range(weights.shape[1]):\n",
    "        wy = yy[(i, j)] * 2 / np.sqrt(3) * 3 / 4\n",
    "        tile_centres_column.append(xx[(i, j)])\n",
    "        tile_centres_row.append(wy)\n",
    "        hex_colours.append(cm.viridis(umatrix[i, j]))\n",
    "        \n",
    "weight_x = []\n",
    "weight_y = []\n",
    "for i in normed_array_doc_vec:\n",
    "    w = som.winner(i)\n",
    "    wx, wy = som.convert_map_to_euclidean(xy=w)\n",
    "    wy = wy * 2 / np.sqrt(3) * 3/4\n",
    "    weight_x.append(wx)\n",
    "    weight_y.append(wy)\n",
    "\n",
    "# convert matplotlib colour palette (RGB float tuple) to bokeh colour palette (hex strings)\n",
    "viridis_plt_hex = [(255 * np.array(i)).astype(int) for i in hex_colours]\n",
    "viridis_bokeh_hex = [RGB(*tuple(rgb)).to_hex() for rgb in viridis_plt_hex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "We plot the hexagonal topology below, using bokeh so we can enable interactivity and thereby allow users to see which pages belong to which clusters of similar content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"outputs/som_visualise_bokeh.html\")\n",
    "\n",
    "fig = figure(title=\"SOM: Hexagonal Topology\",\n",
    "             plot_height=800, plot_width=800,\n",
    "             match_aspect=True,\n",
    "             tools=\"wheel_zoom,save,reset\")\n",
    "\n",
    "source_hex = ColumnDataSource(\n",
    "    data = dict(\n",
    "        x=tile_centres_column,\n",
    "        y=tile_centres_row,\n",
    "        c=viridis_bokeh_hex\n",
    "    )\n",
    ")\n",
    "\n",
    "source_dot = ColumnDataSource(\n",
    "    data=dict(\n",
    "        wx=weight_x,\n",
    "        wy=weight_y,\n",
    "        bp=df_sample['base_path']\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.hex(x='y', y='x', source=source_hex,\n",
    "        size=50 * (.95 / np.sqrt(3)),\n",
    "        alpha=.4,\n",
    "        line_color='gray',\n",
    "        fill_color='c')\n",
    "\n",
    "fig.dot(x='wy', y='wx', source=source_dot,\n",
    "        size=30, \n",
    "        line_color='black')\n",
    "\n",
    "fig.add_tools(HoverTool(\n",
    "    tooltips=[\n",
    "        (\"base_path\", '@bp'), \n",
    "        #(\"(x,y)\", \"($x, $y)\")\n",
    "    ],\n",
    "    mode=\"mouse\", \n",
    "    point_policy=\"follow_mouse\"\n",
    "))\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
